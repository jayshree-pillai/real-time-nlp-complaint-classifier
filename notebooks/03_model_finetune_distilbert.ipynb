{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79560c9-bdca-42de-b8c9-1c46c8038ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f574b1de-4aeb-4eff-85f5-fcae740ac6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 17 17:18:44 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           On  |   00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   42C    P0             39W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-16GB           On  |   00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   43C    P0             38W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-16GB           On  |   00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   44C    P0             42W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-16GB           On  |   00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   45C    P0             41W /  300W |       1MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#to confirm its using the blazing fast GPU\n",
    "#!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a7040c-e2d3-467f-aa80-f3793382202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from dataset import ComplaintDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b37661-6136-4ced-b529-32cb0e6963e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"downloads/complaints_train.csv\")\n",
    "df_clean = df[[\"narrative\", \"product\"]].dropna().astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df_clean[\"product\"])\n",
    "\n",
    "texts = df_clean[\"narrative\"].tolist()\n",
    "labels = le.transform(df_clean[\"product\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd502f-3714-4ef9-b64d-4da1bb571c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch --quiet\n",
    "#!pip install transformers --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4dab9a-2d00-48ce-a67c-5ea33e4cadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Tokenizer, Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "dataset = ComplaintDataset(texts, labels, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67feb793-a382-4782-9319-644e928bd067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dataset.ComplaintDataset'>\n"
     ]
    }
   ],
   "source": [
    "print(ComplaintDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d574b-302c-4bdc-a24b-7eb900b6f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"models/best_model\")\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c2dc2cf-464c-4d8c-8079-9ecc20f494ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1b2dcca-9f95-403d-a091-8d843d2b6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "Epoch 1 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7309/7309 [07:57<00:00, 15.31it/s]\n",
      "Epoch 1 - Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 813/813 [00:21<00:00, 37.97it/s]\n",
      "Epoch 1 | Train Loss: 0.4241 | Val Loss: 0.3512\n",
      "âœ… Best model saved.\n",
      "Epoch 2 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7309/7309 [07:58<00:00, 15.29it/s]\n",
      "Epoch 2 - Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 813/813 [00:21<00:00, 37.77it/s]\n",
      "Epoch 2 | Train Loss: 0.3059 | Val Loss: 0.3412\n",
      "âœ… Best model saved.\n",
      "Epoch 3 - Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7309/7309 [07:58<00:00, 15.28it/s]\n",
      "Epoch 3 - Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 813/813 [00:21<00:00, 37.74it/s]\n",
      "Epoch 3 | Train Loss: 0.2377 | Val Loss: 0.3447\n"
     ]
    }
   ],
   "source": [
    "!python ../src/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6df2f-eda3-4e6a-98df-5461d50b8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64e73eab-6c53-4c9c-a745-2b411eac3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from model import DistilBERTWithCustomHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "018e54ed-52c8-472e-917b-092b58208388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBERTWithCustomHead(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.3, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1: Load model + tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from model import DistilBERTWithCustomHead\n",
    "import torch\n",
    "\n",
    "MODEL_PATH = \"../models/best_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model = DistilBERTWithCustomHead(num_labels=5)  # change if not 5\n",
    "model.load_state_dict(torch.load(f\"{MODEL_PATH}/model.pt\"))\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "264821b4-1226-41ff-9873-6d5c6e8347d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Prepare test data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dataset import ComplaintDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = pd.read_csv(\"../notebooks/downloads/complaints_test.csv\")\n",
    "df_clean = df[[\"narrative\", \"product\"]].dropna().astype(str)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_clean[\"product\"])  # same label order as train\n",
    "\n",
    "texts = df_clean[\"narrative\"].tolist()\n",
    "y_true = le.transform(df_clean[\"product\"].tolist())\n",
    "\n",
    "test_dataset = ComplaintDataset(texts, y_true, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4952817-168e-46a0-a019-a8c511099197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Run inference\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs[\"logits\"]\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e73cea09-53c9-41db-a58d-f7e1b19603c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- NLP Model Evaluation ---\n",
      "Precision: 0.8742638246205822\n",
      "Recall: 0.8297976031686766\n",
      "F1 Score: 0.849505932617285\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "        credit_card       0.79      0.83      0.81      3114\n",
      "   credit_reporting       0.90      0.96      0.93     18235\n",
      "    debt_collection       0.86      0.73      0.79      4630\n",
      "mortgages_and_loans       0.91      0.79      0.85      3798\n",
      "     retail_banking       0.91      0.84      0.87      2707\n",
      "\n",
      "           accuracy                           0.89     32484\n",
      "          macro avg       0.87      0.83      0.85     32484\n",
      "       weighted avg       0.89      0.89      0.88     32484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# ðŸ”¥ Step 3: Print metrics\n",
    "print(\"\\n--- NLP Model Evaluation ---\")\n",
    "print(\"Precision:\", precision_score(y_true, all_preds, average=\"macro\"))\n",
    "print(\"Recall:\", recall_score(y_true, all_preds, average=\"macro\"))\n",
    "print(\"F1 Score:\", f1_score(y_true, all_preds, average=\"macro\"))\n",
    "print(\"\\n\", classification_report(y_true, all_preds, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
