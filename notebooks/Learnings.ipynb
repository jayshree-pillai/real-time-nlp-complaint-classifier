{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713faafc-bd52-4572-ae83-d3dcf889b81f",
   "metadata": {},
   "source": [
    "# üöÄ Deployment Postmortem ‚Äì Complaint Classifier (DistilBERT + LogisticRegression)\n",
    "\n",
    "This document captures all major deployment issues encountered while hosting a DistilBERT-based complaint classifier using AWS SageMaker, and how each was resolved.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Summary\n",
    "\n",
    "- **Model architecture:** DistilBERT embeddings + sklearn LogisticRegression\n",
    "- **Serving method:** `sagemaker.model.Model` with HuggingFace inference container\n",
    "- **Final solution:** Local BERT files + custom `inference.py` + script mode override\n",
    "\n",
    "---\n",
    "\n",
    "## üß® Deployment Errors + Fixes\n",
    "\n",
    "### ‚ùå 1. `ModelInvocationTimeout`\n",
    "**Error:**\n",
    "ModelError: Invocation timed out while waiting for a response from container primary.\n",
    "\n",
    "**Cause:**\n",
    "Model tried to load DistilBERT from HuggingFace at runtime. SageMaker inference containers **don‚Äôt have outbound internet**.\n",
    "\n",
    "**Fix:**\n",
    "- Pre-downloaded DistilBERT model + tokenizer:\n",
    "  ```python\n",
    "  DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\").save_pretrained(\"./bert\")\n",
    "  DistilBertModel.from_pretrained(\"distilbert-base-uncased\").save_pretrained(\"./bert\")\n",
    "\n",
    "  Bundled bert/ folder inside model.tar.gz\n",
    "\n",
    "Updated inference.py to load locally:\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(os.path.join(model_dir, \"bert\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04300207-8fc1-4d4d-a0be-ce46fc4debab",
   "metadata": {},
   "source": [
    "‚ùå 2. TorchServe Backend Crash\n",
    "WorkerThread - Backend worker error\n",
    "Cause:\n",
    "Used PyTorchModel(...), which wraps the model with TorchServe.\n",
    "TorchServe expects .pt files + handler.py, not .joblib + HuggingFace logic.\n",
    "\n",
    "Fix:\n",
    "\n",
    "Switched to raw sagemaker.model.Model() to avoid TorchServe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731846b2-fe6c-4018-b75d-a99b82402321",
   "metadata": {},
   "source": [
    "‚ùå 3. predictor = None\n",
    "HuggingFace container defaulted to TorchServe handler.\n",
    "inference.py was never executed.\n",
    "\n",
    "--handler sagemaker_huggingface_inference_toolkit.handler_service\n",
    "\n",
    "\n",
    "Forced script mode via env:\n",
    "\n",
    "\n",
    "env={\n",
    "  \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
    "  \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4633454-a1f6-4c5a-8b3c-1fc1ace491e0",
   "metadata": {},
   "source": [
    "‚ùå 4. Tokenizer Load Failure\n",
    "Cause:\n",
    "Model attempted to load tokenizer from internet (not allowed).\n",
    "\n",
    "Bundled tokenizer in bert/ folder\n",
    "\n",
    "Loaded using:\n",
    "DistilBertTokenizer.from_pretrained(os.path.join(model_dir, \"bert\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2b2db-f334-4643-bbc9-a334e480f799",
   "metadata": {},
   "source": [
    "‚ùå 5. Misleading Log: ‚ÄúModel_fn found‚Äù\n",
    "\n",
    "model_fn implementation found. It will be used in place of the default one.\n",
    "\n",
    "\n",
    "Cause:\n",
    "TorchServe detected a model_fn() symbol but did not use it properly due to missing handler.py.\n",
    "\n",
    "Fix:\n",
    "\n",
    "Fully exited TorchServe by enabling script mode (see #3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56d3d6-0615-4816-a7b4-2feb927b02bc",
   "metadata": {},
   "source": [
    " Final Setup\n",
    "Deployment Class: sagemaker.model.Model\n",
    "\n",
    "Image URI:\n",
    "763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.13.1-transformers4.26.0-cpu-py39-ubuntu20.04\n",
    "\n",
    "Tarball Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69783d25-ee6e-4364-ae76-c2a875f28334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tar.gz\n",
    "‚îú‚îÄ‚îÄ logreg_model.joblib\n",
    "‚îú‚îÄ‚îÄ label_encoder.joblib\n",
    "‚îú‚îÄ‚îÄ bert/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ config.json\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ pytorch_model.bin or model.safetensors\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_config.json\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ vocab.txt\n",
    "‚îî‚îÄ‚îÄ code/\n",
    "    ‚îî‚îÄ‚îÄ inference.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36bdc28-641c-4126-8912-6562bd3a9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "env={\n",
    "  'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "  'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code'\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
