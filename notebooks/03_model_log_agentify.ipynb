{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e7b8d53-da14-4cd9-8b9a-35164a3b148b",
   "metadata": {},
   "source": [
    "*** Purpose: Human-in-the-loop logging + review-ready feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b970c-211c-4bc5-8679-0fa23ac6196e",
   "metadata": {},
   "source": [
    "#### High LeveL Steps\n",
    "1.Load base DistilBERT (feature extractor only) \n",
    "\n",
    "2.Load the saved logreg_model.joblib and label_encoder.joblib\n",
    "\n",
    "3.Define predict(text) → returns label + confidence\n",
    "\n",
    "4.Load 10 complaint samples from complaints_train.csv\n",
    "\n",
    "5.Loop through and run predict() on each\n",
    "\n",
    "6.Print results clearly (index, predicted label, confidence)\n",
    "\n",
    "7.(Optional) Wrap with agent-style print formatting\n",
    "\n",
    "8.Confirm inference works end-to-end — no missing artifacts, no crashes\n",
    "\n",
    "9.Package model: distilbert_model/, label_encoder.joblib into a .tar.gz\n",
    "\n",
    "10.Upload .tar.gz to S3\n",
    "\n",
    "11.Deploy as SageMaker endpoint with proper inference handler (real-time API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53215e3-29fb-4986-b339-d8763a6dbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch --quiet\n",
    "#!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cedb6897-3900-4982-84f8-ddbdd7ae6857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 — Load base DistilBERT feature extractor\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load tokenizer + base encoder\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "bert.to(device)\n",
    "bert.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7224088d-fdfb-47d9-9519-48b91036d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 — Load classifier and label encoder\n",
    "import joblib\n",
    "\n",
    "clf = joblib.load(\"logreg_model.joblib\")\n",
    "le = joblib.load(\"label_encoder.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dcd37a9-ec0d-4064-96b7-f23624a34c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 — Define predict(text) function\n",
    "def predict(text):\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "    # BERT embedding\n",
    "    with torch.no_grad():\n",
    "        outputs = bert(**inputs)\n",
    "        pooled = outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Mean pooling\n",
    "\n",
    "    # Predict\n",
    "    pred_idx = clf.predict(pooled)[0]\n",
    "    confidence = clf.predict_proba(pooled).max()\n",
    "    label = le.inverse_transform([pred_idx])[0]\n",
    "\n",
    "    return label, confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad2fbf2-caf8-4d62-b5cb-6d6d2feeda12",
   "metadata": {},
   "source": [
    "#### Clasification and Prep for Agentifying Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f17b5f0-633a-4c57-8aff-2301d70f6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Set up logging function\n",
    "import csv\n",
    "from datetime import datetime\n",
    "LOG_FILE = \"agent_log.csv\"\n",
    "def log_prediction(text, predicted_label, confidence, true_label=\"\"):\n",
    "    reviewed = \"No\" if confidence < 0.6 else \"N/A\"\n",
    "    with open(LOG_FILE, mode='a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            datetime.now().isoformat(),\n",
    "            text,\n",
    "            predicted_label,\n",
    "            round(confidence, 4),\n",
    "            reviewed,\n",
    "            true_label\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70627df6-6d58-40d6-b598-08a7c25fca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: If log file doesn't exist, add header\n",
    "import os\n",
    "\n",
    "if not os.path.exists(LOG_FILE):\n",
    "    with open(LOG_FILE, mode='w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"timestamp\", \"text\", \"predicted_label\", \"confidence\", \"reviewed\", \"true_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28ec2c85-24a9-4a3c-81b2-6da43f76ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 — Test on sample complaints\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"downloads/complaints_train.csv\")\n",
    "texts = df[\"narrative\"].dropna().astype(str).tolist()[:1000]\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    label, conf = predict(text)\n",
    "    log_prediction(text, label, conf)\n",
    "    print(f\"[{i+1}] → {label} (confidence: {conf:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5191f980-a4a5-4b7c-ac56-31f4b655884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘/home/ec2-user/SageMaker/lost+found’: Permission denied\n",
      "/home/ec2-user/SageMaker/complaint-classifier/notebooks/logreg_model.joblib\n"
     ]
    }
   ],
   "source": [
    "!find /home/ec2-user -name \"logreg_model.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb25ce97-ed0f-493d-9a9c-fd2a72096c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Move the golden copy to #S3/complaint-classifier-jp2025/models\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket = 'complaint-classifier-jp2025'\n",
    "prefix = 'models/'\n",
    "\n",
    "# Absolute paths\n",
    "logreg_path = '/home/ec2-user/SageMaker/complaint-classifier/notebooks/logreg_model.joblib'\n",
    "label_path = '/home/ec2-user/SageMaker/complaint-classifier/notebooks/label_encoder.joblib'\n",
    "\n",
    "# Upload to S3\n",
    "s3.upload_file(logreg_path, bucket, prefix + 'logreg_model.joblib')\n",
    "s3.upload_file(label_path, bucket, prefix + 'label_encoder.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
