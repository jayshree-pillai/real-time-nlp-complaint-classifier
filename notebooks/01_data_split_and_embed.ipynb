{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b698a4-3072-406f-905a-513a00c5cc48",
   "metadata": {},
   "source": [
    "### S3 Tie UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c78faea-fde6-4699-9b8d-3b376839c911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['s3://complaint-classifier-jp2025/data',\n",
       " 's3://complaint-classifier-jp2025/data/X_train_full.npy',\n",
       " 's3://complaint-classifier-jp2025/data/complaints_processed.csv',\n",
       " 's3://complaint-classifier-jp2025/data/test/complaints_test.csv/complaints_test.csv',\n",
       " 's3://complaint-classifier-jp2025/data/train/complaints_train.csv/complaints_train.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1 — S3 config\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "\n",
    "bucket = \"complaint-classifier-jp2025\"\n",
    "prefix = \"data\"\n",
    "s3_uri = f\"s3://{bucket}/{prefix}/\"\n",
    "\n",
    "# Confirm file is there\n",
    "S3Downloader.list(s3_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f89b891-b04c-47db-88e5-1cb40fee9f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'product', 'narrative']\n"
     ]
    }
   ],
   "source": [
    "# Shuffle and split the data into *train and *test.csv files and store it back to S3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os \n",
    "\n",
    "s3_file_uri = f\"s3://{bucket}/{prefix}/complaints_processed.csv\"\n",
    "## ONLY DO IT ONCE to Save to Downloads folder\n",
    "#os.makedirs(\"downloads\", exist_ok=True)\n",
    "#S3Downloader.download(s3_uri, \"downloads\")\n",
    "#S3Downloader.download(s3_file_uri, local_file)\n",
    "\n",
    "# Load and shuffle\n",
    "df = pd.read_csv(\"downloads/complaints_processed.csv\")\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1a4262-05bd-480b-8058-1a987f82c739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test CSVs uploaded to S3.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42,stratify=df['product'])\n",
    "\n",
    "# Save locally\n",
    "train_df.to_csv(\"complaints_train.csv\", index=False)\n",
    "test_df.to_csv(\"complaints_test.csv\", index=False)\n",
    "\n",
    "### ONLY DO IT ONCE to Save to Downloads folder\n",
    "# Upload to S3\n",
    "s3_prefix = f\"s3://{bucket}/{prefix}\"\n",
    "#S3Uploader.upload(\"complaints_train.csv\", f\"{s3_prefix}/train/complaints_train.csv\")\n",
    "#S3Uploader.upload(\"complaints_test.csv\", f\"{s3_prefix}/test/complaints_test.csv\")\n",
    "\n",
    "print(\"Train and test CSVs uploaded to S3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43366862-2c65-46e2-9637-d58e125cbcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --quiet\n",
    "!pip install transformers --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93248f5b-b43f-48b2-9698-2a929ba734f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff0000; text-decoration-color: #ff0000\">╭─────────────────────────────── </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">Traceback </span><span style=\"color: #ff7f7f; text-decoration-color: #ff7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #ff0000; text-decoration-color: #ff0000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> in &lt;module&gt;:1                                                                                    <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>                                                                                                  <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 1 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">torch</span>                                                                                <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">numpy</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">np</span>                                                                          <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">transformers</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> DistilBertTokenizer, DistilBertModel                               <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">tqdm</span><span style=\"color: #808080; text-decoration-color: #808080\"> </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> tqdm                                                                       <span style=\"color: #ff0000; text-decoration-color: #ff0000\">│</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008700; text-decoration-color: #008700\">'torch'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;0;0m╭─\u001b[0m\u001b[38;2;255;0;0m──────────────────────────────\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[1;38;2;255;0;0mTraceback \u001b[0m\u001b[1;2;38;2;255;0;0m(most recent call last)\u001b[0m\u001b[38;2;255;0;0m \u001b[0m\u001b[38;2;255;0;0m───────────────────────────────\u001b[0m\u001b[38;2;255;0;0m─╮\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m in <module>:1                                                                                    \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m                                                                                                  \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m \u001b[31m❱ \u001b[0m 1 \u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mtorch\u001b[0m                                                                                \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[94mimport\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mnumpy\u001b[0m\u001b[90m \u001b[0m\u001b[94mas\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mnp\u001b[0m                                                                          \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mtransformers\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m DistilBertTokenizer, DistilBertModel                               \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mfrom\u001b[0m\u001b[90m \u001b[0m\u001b[4;96mtqdm\u001b[0m\u001b[90m \u001b[0m\u001b[94mimport\u001b[0m tqdm                                                                       \u001b[38;2;255;0;0m│\u001b[0m\n",
       "\u001b[38;2;255;0;0m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[38;2;0;135;0m'torch'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 🔹 Config\n",
    "bucket = \"complaint-classifier-jp2025\"\n",
    "s3_output = f\"s3://{bucket}/models/X_train.npy\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 🔹 Load DistilBERT\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Download complaints_train.csv from S3\n",
    "s3_csv_uri = \"s3://complaint-classifier-jp2025/data/train/complaints_train.csv\"\n",
    "os.makedirs(\"downloads\", exist_ok=True)\n",
    "S3Downloader.download(s3_csv_uri, \"downloads\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13da879e-03b1-4dc7-b1ee-f5e9850d6e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🔹 Load CSV\n",
    "df = pd.read_csv(\"downloads/complaints_train.csv\")\n",
    "texts = df[\"narrative\"].dropna().astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a4b526-daf6-48b8-b896-a94cf777f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129927 s3://complaint-classifier-jp2025/data\n"
     ]
    }
   ],
   "source": [
    "s3_uri = 's3://complaint-classifier-jp2025/data'\n",
    "print(len(texts),s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37e43cea-2c2f-4280-9ed3-6db4fb8fb92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8121/8121 [07:20<00:00, 18.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Uploaded full embedding to S3: s3://complaint-classifier-jp2025/data/X_train_full.npy\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Embed in batches\n",
    "batch_size = 16\n",
    "embeddings = []\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch = texts[i:i + batch_size]\n",
    "    encodings = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    input_ids = encodings[\"input_ids\"].to(device)\n",
    "    attention_mask = encodings[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_batch = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(cls_batch)\n",
    "\n",
    "# 🔹 Save + Upload\n",
    "X_train = np.concatenate(embeddings, axis=0)\n",
    "np.save(\"X_train_full.npy\", X_train)\n",
    "S3Uploader.upload(\"X_train_full.npy\", s3_uri)\n",
    "print(\"✅ Uploaded full embedding to S3:\", s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9617a492-332f-4d3d-a970-86186c3a3ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129927, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(\"X_train_full.npy\").shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2252d7d-8aa5-4b19-8568-2dfc8171ff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://complaint-classifier-jp2025/data/X_train_full.npy/X_train_full.npy'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#S3Uploader.upload(\"X_train_full.npy\", \"s3://complaint-classifier-jp2025/data/X_train_full.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0a3f2a-7e52-4c9f-a4d5-63e297c7079f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LABEL ENCODING + Model Training\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"downloads/complaints_train.csv\")\n",
    "texts = df[\"narrative\"].dropna().astype(str).tolist()\n",
    "\n",
    "valid_idx = df[\"narrative\"].dropna().index\n",
    "labels = df.loc[valid_idx, \"product\"].astype(str).tolist()\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(labels)\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(le, 'label_encoder.joblib')\n",
    "\n",
    "len(texts) == len(y_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4f550e-140f-4174-b45d-a93058041fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "X = np.load('X_train_full.npy')\n",
    "assert X.shape[0] == len(y_encoded), \"Mismatch in features and labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b8c917-0e6f-4936-95aa-ffb98eb4fcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "        credit_card       0.72      0.67      0.69     12452\n",
      "   credit_reporting       0.87      0.92      0.89     72937\n",
      "    debt_collection       0.74      0.62      0.67     18518\n",
      "mortgages_and_loans       0.79      0.77      0.78     15192\n",
      "     retail_banking       0.79      0.79      0.79     10828\n",
      "\n",
      "           accuracy                           0.82    129927\n",
      "          macro avg       0.78      0.75      0.77    129927\n",
      "       weighted avg       0.82      0.82      0.82    129927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)\n",
    "clf.fit(X, y_encoded)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(clf, 'logreg_model.joblib')\n",
    "\n",
    "# Optional: quick check\n",
    "y_pred = clf.predict(X)\n",
    "print(classification_report(y_encoded, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca6c558-8727-42a9-be6d-ce94db137dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
